{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPJeavymKhhmnvOIEmWZ3PD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ffcc9a37d08b4ca09090097ff304d42a": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_9836c9b2e91b4dd9b1f63b091ae070e8",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "segmentation         \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:00\u001b[0m\nspeaker_counting     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:00\u001b[0m\nembeddings           \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:30\u001b[0m\ndiscrete_diarization \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">segmentation         <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span>\nspeaker_counting     <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span>\nembeddings           <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:30</span>\ndiscrete_diarization <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "9836c9b2e91b4dd9b1f63b091ae070e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VihaanChhabria/congress-llm/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0gxfFFf-Ryl",
        "outputId": "ed990434-8c73-4547-cf71-9e4b9091b800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-whisper\n",
        "!pip install pyannote-audio\n",
        "!pip install torchvision==0.23.0 --no-dependencies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "IR3IRAIjAh4A",
        "outputId": "983c8e7b-bbb6-4c18-d80c-ac102dddae5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.12/dist-packages (20250625)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton>=2->openai-whisper) (75.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.13.1.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.3)\n",
            "Requirement already satisfied: pyannote-audio in /usr/local/lib/python3.12/dist-packages (4.0.3)\n",
            "Requirement already satisfied: asteroid-filterbanks>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio) (0.4.0)\n",
            "Requirement already satisfied: einops>=0.8.1 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio) (0.8.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio) (0.36.0)\n",
            "Requirement already satisfied: lightning>=2.4 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio) (2.6.0)\n",
            "Requirement already satisfied: matplotlib>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio) (3.10.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.34.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp>=1.34.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.34.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio) (1.39.1)\n",
            "Requirement already satisfied: pyannote-core>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio) (6.0.1)\n",
            "Requirement already satisfied: pyannote-database>=6.1.1 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio) (6.1.1)\n",
            "Requirement already satisfied: pyannote-metrics>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio) (4.0.0)\n",
            "Requirement already satisfied: pyannote-pipeline>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio) (4.0.0)\n",
            "Requirement already satisfied: pyannoteai-sdk>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio) (0.3.0)\n",
            "Requirement already satisfied: pytorch-metric-learning>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio) (2.9.0)\n",
            "Requirement already satisfied: rich>=13.9.4 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio) (13.9.4)\n",
            "Requirement already satisfied: safetensors>=0.5.2 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio) (0.7.0)\n",
            "Requirement already satisfied: soundfile>=0.13.1 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio) (0.13.1)\n",
            "Requirement already satisfied: torch-audiomentations>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio) (0.12.0)\n",
            "Requirement already satisfied: torch==2.8.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio) (2.8.0)\n",
            "Requirement already satisfied: torchaudio==2.8.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio) (2.8.0)\n",
            "Requirement already satisfied: torchcodec==0.7.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio) (0.7.0)\n",
            "Requirement already satisfied: torchmetrics>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio) (1.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->pyannote-audio) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->pyannote-audio) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->pyannote-audio) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->pyannote-audio) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->pyannote-audio) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->pyannote-audio) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->pyannote-audio) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->pyannote-audio) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->pyannote-audio) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->pyannote-audio) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->pyannote-audio) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->pyannote-audio) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->pyannote-audio) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->pyannote-audio) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->pyannote-audio) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->pyannote-audio) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->pyannote-audio) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->pyannote-audio) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->pyannote-audio) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->pyannote-audio) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->pyannote-audio) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->pyannote-audio) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from asteroid-filterbanks>=0.4.0->pyannote-audio) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.28.1->pyannote-audio) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.28.1->pyannote-audio) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.28.1->pyannote-audio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.28.1->pyannote-audio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.28.1->pyannote-audio) (1.2.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from lightning>=2.4->pyannote-audio) (0.15.2)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/dist-packages (from lightning>=2.4->pyannote-audio) (2.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.10.0->pyannote-audio) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.10.0->pyannote-audio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.10.0->pyannote-audio) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.10.0->pyannote-audio) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.10.0->pyannote-audio) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.10.0->pyannote-audio) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.10.0->pyannote-audio) (2.9.0.post0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.34.0->pyannote-audio) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp>=1.34.0->pyannote-audio) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp>=1.34.0->pyannote-audio) (1.39.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.39.1->opentelemetry-exporter-otlp>=1.34.0->pyannote-audio) (1.72.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.63.2 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.39.1->opentelemetry-exporter-otlp>=1.34.0->pyannote-audio) (1.76.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.39.1->opentelemetry-exporter-otlp>=1.34.0->pyannote-audio) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.39.1->opentelemetry-exporter-otlp>=1.34.0->pyannote-audio) (1.39.1)\n",
            "Requirement already satisfied: protobuf<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.39.1->opentelemetry-exporter-otlp-proto-grpc==1.39.1->opentelemetry-exporter-otlp>=1.34.0->pyannote-audio) (5.29.5)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.34.0->pyannote-audio) (0.60b1)\n",
            "Requirement already satisfied: pandas>=2.2.3 in /usr/local/lib/python3.12/dist-packages (from pyannote-core>=6.0.1->pyannote-audio) (2.3.3)\n",
            "Requirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-core>=6.0.1->pyannote-audio) (2.4.0)\n",
            "Collecting numpy (from asteroid-filterbanks>=0.4.0->pyannote-audio)\n",
            "  Using cached numpy-2.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from pyannote-metrics>=4.0.0->pyannote-audio) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from pyannote-metrics>=4.0.0->pyannote-audio) (1.16.3)\n",
            "Requirement already satisfied: optuna>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-pipeline>=4.0.0->pyannote-audio) (4.6.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.9.4->pyannote-audio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.9.4->pyannote-audio) (2.19.2)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.13.1->pyannote-audio) (2.0.0)\n",
            "Requirement already satisfied: julius<0.3,>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from torch-audiomentations>=0.12.0->pyannote-audio) (0.2.7)\n",
            "Requirement already satisfied: torch-pitch-shift>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from torch-audiomentations>=0.12.0->pyannote-audio) (1.2.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.13.1->pyannote-audio) (2.23)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning>=2.4->pyannote-audio) (3.13.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.34.0->pyannote-audio) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->pyannote-audio) (0.1.2)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna>=4.2.0->pyannote-pipeline>=4.0.0->pyannote-audio) (1.17.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna>=4.2.0->pyannote-pipeline>=4.0.0->pyannote-audio) (6.10.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna>=4.2.0->pyannote-pipeline>=4.0.0->pyannote-audio) (2.0.45)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->pyannote-core>=6.0.1->pyannote-audio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->pyannote-core>=6.0.1->pyannote-audio) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.10.0->pyannote-audio) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.28.1->pyannote-audio) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.28.1->pyannote-audio) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.28.1->pyannote-audio) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.28.1->pyannote-audio) (2025.11.12)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.1->pyannote-metrics>=4.0.0->pyannote-audio) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.1->pyannote-metrics>=4.0.0->pyannote-audio) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.8.0->pyannote-audio) (1.3.0)\n",
            "Requirement already satisfied: primePy>=1.3 in /usr/local/lib/python3.12/dist-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.12.0->pyannote-audio) (1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.8.0->pyannote-audio) (3.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.4->pyannote-audio) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.4->pyannote-audio) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.4->pyannote-audio) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.4->pyannote-audio) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.4->pyannote-audio) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.4->pyannote-audio) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.4->pyannote-audio) (1.22.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna>=4.2.0->pyannote-pipeline>=4.0.0->pyannote-audio) (1.3.10)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna>=4.2.0->pyannote-pipeline>=4.0.0->pyannote-audio) (3.3.0)\n",
            "Using cached numpy-2.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.0 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.0 which is incompatible.\n",
            "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.8.0 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.4.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "fd3bc22016fa4da6ac3fa9649d20cfac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchvision==0.23.0\n",
            "  Downloading torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Downloading torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl (8.6 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/8.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m8.3/8.6 MB\u001b[0m \u001b[31m250.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m126.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchvision\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.24.0+cu126\n",
            "    Uninstalling torchvision-0.24.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.24.0+cu126\n",
            "Successfully installed torchvision-0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_path = \"/content/drive/My Drive/Colab Notebooks/audio.m4a\""
      ],
      "metadata": {
        "id": "FQVgxIdeCwTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### transcription setup #####\n",
        "\n",
        "import whisper\n",
        "import os\n",
        "\n",
        "model = whisper.load_model(\"tiny.en\")\n",
        "result = model.transcribe(audio_path, verbose=True)\n",
        "\n",
        "# Each segment has start, end, and text\n",
        "for segment in result['segments']:\n",
        "    print(segment['start'], segment['end'], segment['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8Oe5Z6MBAf9S",
        "outputId": "69a7a148-28f5-460f-a0cb-e13c626b9e0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 72.1M/72.1M [00:01<00:00, 46.8MiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:06.720]  They can spend more money on enrichment activities, extra-curriculars, rich high school\n",
            "[00:06.720 --> 00:12.320]  dropouts, staying at the top as much as poor college graduates stay in the bottom from 14-16%.\n",
            "[00:12.320 --> 00:17.880]  It gets worse when you factor in race, as historical divides and wealth created by decades\n",
            "[00:17.880 --> 00:23.320]  of redlining, slavery, Jim Crow laws, Chinese and Sluge and the literal internment camps\n",
            "[00:23.320 --> 00:25.640]  that we put Japanese people in.\n",
            "[00:25.640 --> 00:30.400]  More aspirants who only want to pursue the American dream, they were promised or instead\n",
            "[00:30.400 --> 00:34.800]  burdened with college debts that keep them held under, drowning in the river of lies promised\n",
            "[00:34.800 --> 00:36.800]  by our founding fathers.\n",
            "[00:36.800 --> 00:39.160]  Blind hiring sounds like a good thing.\n",
            "[00:39.160 --> 00:40.160]  Keyword sounds.\n",
            "[00:40.160 --> 00:42.280]  Let's do a quick case study.\n",
            "[00:42.280 --> 00:44.080]  You have two potential employees.\n",
            "[00:44.080 --> 00:48.120]  The first candidate has a bachelor's degree but comes from a well-off upper-class middle\n",
            "[00:48.120 --> 00:51.520]  family and has whistle legacy to their college.\n",
            "[00:51.520 --> 00:55.000]  The second candidate, they come from family and four with a single mother.\n",
            "[00:55.000 --> 00:58.840]  They live off of food stamps and have to fight tooth and nail doing every extracurricular\n",
            "[00:58.840 --> 01:02.440]  living off of caffeine for the entirety of high school just so that they can get into\n",
            "[01:02.440 --> 01:03.760]  a decent college.\n",
            "[01:03.760 --> 01:05.880]  But they also have a bachelor's degree.\n",
            "[01:05.880 --> 01:08.800]  Blind hiring tells you that these two candidates are equal.\n",
            "[01:08.800 --> 01:12.520]  Morality tells you that one of these candidates needs it.\n",
            "[01:12.520 --> 01:14.720]  So, senators, I ask you to consider this.\n",
            "[01:14.720 --> 01:21.120]  Don't question which candidate is more qualified but rather which one needs it more\n",
            "[01:21.200 --> 01:28.000]  because in the questions of equal qualification, the question of need comes up to the employer.\n",
            "[01:28.000 --> 01:30.840]  Blind hiring requires you to completely ignore backgrounds.\n",
            "[01:30.840 --> 01:35.600]  Morality asks you to combat centuries of the balance with as much as you can do which is\n",
            "[01:35.600 --> 01:38.480]  to give the needy candidate the job that they need.\n",
            "[01:38.480 --> 01:42.680]  If morals don't make your heart grow through sizes, look to the economy instead.\n",
            "[01:42.680 --> 01:48.600]  According to the Imperial College of London, wealth gap leads to political and economic instability.\n",
            "[01:48.600 --> 01:55.000]  If you really want inequality, you will look to the background of these citizens.\n",
            "[01:55.000 --> 01:59.600]  Regarding previous Senator Cinderglepalli uses the EU as an example but the wealth gap between\n",
            "[01:59.600 --> 02:02.160]  the United States and the EU is completely different.\n",
            "[02:02.160 --> 02:09.160]  In the United States, a top 10% owns 71% of the wealth unlike in the EU.\n",
            "[02:09.160 --> 02:13.480]  And again unconscious bias is not solved in later stages of interview.\n",
            "[02:13.480 --> 02:18.400]  The problem with blind hiring is that maybe it's time for America to stop the incline\n",
            "[02:18.400 --> 02:22.640]  to the cesspool of inequality that it has created over its rough colonialist rights\n",
            "[02:22.640 --> 02:27.560]  of premises history and start being proactive and open its eyes to actually try and\n",
            "[02:27.560 --> 02:29.200]  dissolve these problems.\n",
            "[02:29.200 --> 02:33.360]  Maybe it's time we consider which candidate needs it and stop telling ourselves that we\n",
            "[02:33.360 --> 02:37.680]  live in a meritocracy because we don't and it's time to put ourselves in the forefront\n",
            "[02:37.680 --> 02:39.480]  of solving this issue.\n",
            "[02:39.480 --> 02:40.480]  Thank you.\n",
            "[02:40.480 --> 02:43.640]  Thank you, BSB for two minutes and for seven seconds.\n",
            "[02:43.640 --> 02:46.520]  I will eat two minutes and for seven seconds.\n",
            "[02:47.520 --> 02:50.520]  We're now launching two blocks of questioning, all questioners, please rise.\n",
            "[02:50.520 --> 03:03.000]  That will first go to Senator\n",
            "[03:03.000 --> 03:04.000]  BSB.\n",
            "[03:04.000 --> 03:05.000]  Sorry.\n",
            "[03:05.000 --> 03:11.000]  So, D-I-Nishes and World Backages in some sense what we're still proposing.\n",
            "[03:11.000 --> 03:15.520]  So you're saying we should be fine now because I'm saying the D-I-Nishes which are having\n",
            "[03:15.520 --> 03:18.000]  those people right now have already been rolled back.\n",
            "[03:18.000 --> 03:21.560]  So right now the only thing that's facing them is the bias itself.\n",
            "[03:21.560 --> 03:26.000]  What then distinguishes D-I and the process of them is you can build that we're not\n",
            "[03:26.000 --> 03:28.040]  in the middle of the problem.\n",
            "[03:28.040 --> 03:32.320]  Senator, what is stopping these candidates from telling the interviewers about their background\n",
            "[03:32.320 --> 03:34.320]  in the interview where there is more objectives.\n",
            "[03:34.320 --> 03:37.060]  There's nothing stopping the candidate, there's something stopping the interviewer from\n",
            "[03:37.060 --> 03:39.220]  considering which is when your bill stipulates.\n",
            "[03:39.220 --> 03:41.740]  Why can't they consider during the interview stage?\n",
            "[03:41.740 --> 03:45.680]  This is at the beginning of the interview, the interviewer cannot consider the candidate\n",
            "[03:45.680 --> 03:46.680]  back.\n",
            "[03:46.680 --> 03:50.720]  That's not part of the actual interview stage, the actual interview stage will be actually\n",
            "[03:50.720 --> 03:52.000]  interacting with each other.\n",
            "[03:52.000 --> 03:55.100]  Well, the interact with each other might have the candidate telling the interviewer\n",
            "[03:55.100 --> 03:57.140]  about their background.\n",
            "[03:57.140 --> 04:00.100]  We should be considering the front of the beginning of the question, if you're just\n",
            "[04:00.100 --> 04:02.100]  laughing, speak or maybe speak.\n",
            "[04:02.100 --> 04:04.100]  I'm going to put your flapper.\n",
            "[04:04.100 --> 04:05.100]  Thank you, Chair.\n",
            "[04:05.100 --> 04:06.100]  Good, thanks, sir.\n",
            "0.0 6.72  They can spend more money on enrichment activities, extra-curriculars, rich high school\n",
            "6.72 12.32  dropouts, staying at the top as much as poor college graduates stay in the bottom from 14-16%.\n",
            "12.32 17.88  It gets worse when you factor in race, as historical divides and wealth created by decades\n",
            "17.88 23.32  of redlining, slavery, Jim Crow laws, Chinese and Sluge and the literal internment camps\n",
            "23.32 25.64  that we put Japanese people in.\n",
            "25.64 30.4  More aspirants who only want to pursue the American dream, they were promised or instead\n",
            "30.4 34.8  burdened with college debts that keep them held under, drowning in the river of lies promised\n",
            "34.8 36.8  by our founding fathers.\n",
            "36.8 39.16  Blind hiring sounds like a good thing.\n",
            "39.16 40.16  Keyword sounds.\n",
            "40.16 42.28  Let's do a quick case study.\n",
            "42.28 44.08  You have two potential employees.\n",
            "44.08 48.120000000000005  The first candidate has a bachelor's degree but comes from a well-off upper-class middle\n",
            "48.120000000000005 51.519999999999996  family and has whistle legacy to their college.\n",
            "51.519999999999996 55.0  The second candidate, they come from family and four with a single mother.\n",
            "55.0 58.84  They live off of food stamps and have to fight tooth and nail doing every extracurricular\n",
            "58.84 62.44  living off of caffeine for the entirety of high school just so that they can get into\n",
            "62.44 63.76  a decent college.\n",
            "63.76 65.88  But they also have a bachelor's degree.\n",
            "65.88 68.8  Blind hiring tells you that these two candidates are equal.\n",
            "68.8 72.52  Morality tells you that one of these candidates needs it.\n",
            "72.52 74.72  So, senators, I ask you to consider this.\n",
            "74.72 81.12  Don't question which candidate is more qualified but rather which one needs it more\n",
            "81.2 88.0  because in the questions of equal qualification, the question of need comes up to the employer.\n",
            "88.0 90.84  Blind hiring requires you to completely ignore backgrounds.\n",
            "90.84 95.60000000000001  Morality asks you to combat centuries of the balance with as much as you can do which is\n",
            "95.60000000000001 98.48  to give the needy candidate the job that they need.\n",
            "98.48 102.68  If morals don't make your heart grow through sizes, look to the economy instead.\n",
            "102.68 108.60000000000001  According to the Imperial College of London, wealth gap leads to political and economic instability.\n",
            "108.6 115.0  If you really want inequality, you will look to the background of these citizens.\n",
            "115.0 119.6  Regarding previous Senator Cinderglepalli uses the EU as an example but the wealth gap between\n",
            "119.6 122.16  the United States and the EU is completely different.\n",
            "122.16 129.16  In the United States, a top 10% owns 71% of the wealth unlike in the EU.\n",
            "129.16 133.48  And again unconscious bias is not solved in later stages of interview.\n",
            "133.48 138.4  The problem with blind hiring is that maybe it's time for America to stop the incline\n",
            "138.4 142.64000000000001  to the cesspool of inequality that it has created over its rough colonialist rights\n",
            "142.64000000000001 147.56  of premises history and start being proactive and open its eyes to actually try and\n",
            "147.56 149.20000000000002  dissolve these problems.\n",
            "149.20000000000002 153.36  Maybe it's time we consider which candidate needs it and stop telling ourselves that we\n",
            "153.36 157.68  live in a meritocracy because we don't and it's time to put ourselves in the forefront\n",
            "157.68 159.48000000000002  of solving this issue.\n",
            "159.48000000000002 160.48000000000002  Thank you.\n",
            "160.48000000000002 163.64000000000001  Thank you, BSB for two minutes and for seven seconds.\n",
            "163.64000000000001 166.52  I will eat two minutes and for seven seconds.\n",
            "167.52 170.52  We're now launching two blocks of questioning, all questioners, please rise.\n",
            "170.52 183.0  That will first go to Senator\n",
            "183.0 184.0  BSB.\n",
            "184.0 185.0  Sorry.\n",
            "185.0 191.0  So, D-I-Nishes and World Backages in some sense what we're still proposing.\n",
            "191.0 195.52  So you're saying we should be fine now because I'm saying the D-I-Nishes which are having\n",
            "195.52 198.0  those people right now have already been rolled back.\n",
            "198.0 201.56  So right now the only thing that's facing them is the bias itself.\n",
            "201.56 206.0  What then distinguishes D-I and the process of them is you can build that we're not\n",
            "206.0 208.04  in the middle of the problem.\n",
            "208.04 212.32  Senator, what is stopping these candidates from telling the interviewers about their background\n",
            "212.32 214.32  in the interview where there is more objectives.\n",
            "214.32 217.06  There's nothing stopping the candidate, there's something stopping the interviewer from\n",
            "217.06 219.22  considering which is when your bill stipulates.\n",
            "219.22 221.73999999999998  Why can't they consider during the interview stage?\n",
            "221.73999999999998 225.68  This is at the beginning of the interview, the interviewer cannot consider the candidate\n",
            "225.68 226.68  back.\n",
            "226.68 230.72  That's not part of the actual interview stage, the actual interview stage will be actually\n",
            "230.72 232.0  interacting with each other.\n",
            "232.0 235.1  Well, the interact with each other might have the candidate telling the interviewer\n",
            "235.1 237.14  about their background.\n",
            "237.14 240.1  We should be considering the front of the beginning of the question, if you're just\n",
            "240.1 242.1  laughing, speak or maybe speak.\n",
            "242.1 244.1  I'm going to put your flapper.\n",
            "244.1 245.1  Thank you, Chair.\n",
            "245.1 246.1  Good, thanks, sir.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### diarization setup ####\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "from pyannote.audio import Pipeline\n",
        "from pyannote.audio.pipelines.utils.hook import ProgressHook\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "# Define a path for the converted WAV file\n",
        "converted_audio_path = \"/content/drive/My Drive/Colab Notebooks/audio_converted.wav\"\n",
        "\n",
        "# Load the M4A file and save it as WAV using torchaudio\n",
        "print(f\"Converting {audio_path} to WAV...\")\n",
        "waveform, sample_rate = torchaudio.load(audio_path)\n",
        "torchaudio.save(converted_audio_path, waveform, sample_rate)\n",
        "print(f\"Conversion complete. Saved to {converted_audio_path}\")\n",
        "\n",
        "pipeline = Pipeline.from_pretrained(\n",
        "    \"pyannote/speaker-diarization-community-1\",\n",
        "    token=userdata.get('pyannoteKey'))\n",
        "\n",
        "pipeline.to(torch.device(\"cuda\"))\n",
        "\n",
        "print(\"Processing converted audio.wav\")\n",
        "\n",
        "with ProgressHook() as hook:\n",
        "    output = pipeline(converted_audio_path, hook=hook)\n",
        "\n",
        "for turn, speaker in output.speaker_diarization:\n",
        "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800,
          "referenced_widgets": [
            "ffcc9a37d08b4ca09090097ff304d42a",
            "9836c9b2e91b4dd9b1f63b091ae070e8"
          ]
        },
        "id": "8t_TUQ57BxE8",
        "outputId": "d8920167-3f9a-4dd9-ee9b-cbb09272e1b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting /content/drive/My Drive/Colab Notebooks/audio.m4a to WAV...\n",
            "Conversion complete. Saved to /content/drive/My Drive/Colab Notebooks/audio_converted.wav\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffcc9a37d08b4ca09090097ff304d42a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing converted audio.wav\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/usr/local/lib/python3.12/dist-packages/pyannote/audio/models/blocks/pooling.py:103: UserWarning: std(): degrees of\n",
              "freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output \n",
              "numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1839.)\n",
              "  std = sequences.std(dim=-1, correction=1)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pyannote/audio/models/blocks/pooling.py:103: UserWarning: std(): degrees of\n",
              "freedom is &lt;= 0. Correction should be strictly less than the reduction factor (input numel divided by output \n",
              "numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1839.)\n",
              "  std = sequences.std(dim=-1, correction=1)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start=0.0s stop=1.5s speaker_SPEAKER_03\n",
            "start=1.8s stop=12.7s speaker_SPEAKER_03\n",
            "start=6.0s stop=6.2s speaker_SPEAKER_02\n",
            "start=13.1s stop=24.7s speaker_SPEAKER_03\n",
            "start=25.5s stop=36.1s speaker_SPEAKER_03\n",
            "start=36.6s stop=65.4s speaker_SPEAKER_03\n",
            "start=65.6s stop=71.9s speaker_SPEAKER_03\n",
            "start=72.4s stop=74.3s speaker_SPEAKER_03\n",
            "start=74.5s stop=86.5s speaker_SPEAKER_03\n",
            "start=87.8s stop=90.3s speaker_SPEAKER_03\n",
            "start=90.6s stop=97.7s speaker_SPEAKER_03\n",
            "start=98.3s stop=102.1s speaker_SPEAKER_03\n",
            "start=102.5s stop=107.7s speaker_SPEAKER_03\n",
            "start=108.5s stop=113.9s speaker_SPEAKER_03\n",
            "start=114.8s stop=128.0s speaker_SPEAKER_03\n",
            "start=128.9s stop=132.8s speaker_SPEAKER_03\n",
            "start=133.4s stop=159.0s speaker_SPEAKER_03\n",
            "start=149.1s stop=149.2s speaker_SPEAKER_00\n",
            "start=159.0s stop=159.0s speaker_SPEAKER_01\n",
            "start=160.0s stop=160.1s speaker_SPEAKER_01\n",
            "start=161.4s stop=170.9s speaker_SPEAKER_01\n",
            "start=171.0s stop=171.1s speaker_SPEAKER_01\n",
            "start=171.2s stop=174.0s speaker_SPEAKER_01\n",
            "start=174.2s stop=185.8s speaker_SPEAKER_00\n",
            "start=186.2s stop=193.8s speaker_SPEAKER_03\n",
            "start=193.7s stop=201.1s speaker_SPEAKER_00\n",
            "start=201.2s stop=206.4s speaker_SPEAKER_03\n",
            "start=206.4s stop=214.2s speaker_SPEAKER_02\n",
            "start=214.2s stop=227.0s speaker_SPEAKER_03\n",
            "start=214.2s stop=214.4s speaker_SPEAKER_02\n",
            "start=215.1s stop=215.6s speaker_SPEAKER_02\n",
            "start=225.5s stop=227.0s speaker_SPEAKER_02\n",
            "start=227.0s stop=227.0s speaker_SPEAKER_03\n",
            "start=227.0s stop=246.0s speaker_SPEAKER_02\n"
          ]
        }
      ]
    }
  ]
}